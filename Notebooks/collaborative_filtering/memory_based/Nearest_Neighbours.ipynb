{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_like_df = pd.read_csv(path/'ml/EDA/outputs/track_like_df.csv')\n",
    "track_like_df = track_like_df[['USER_ID', 'TRACK_ID']].assign(r=1/6.771349)\n",
    "track_like_df.columns = ['user', 'track', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_download_df = pd.read_csv(path/'ml/EDA/outputs/track_download_df.csv')\n",
    "track_download_df = track_download_df[['USER_ID', 'TRACK_ID']].assign(r=1/30.983061)\n",
    "track_download_df.columns = ['user', 'track', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_purchase_df = pd.read_csv(path/'ml/EDA/outputs/track_purchase_df.csv')\n",
    "track_purchase_df = track_purchase_df[['USER_ID','TRACK_ID']].assign(r=1/11.416511)\n",
    "track_purchase_df.columns = ['user','track','score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16612906, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.concat([track_download_df, track_like_df, track_purchase_df])\n",
    "total = total.groupby(['user', 'track']).score.sum().reset_index()\n",
    "total['score'] = total['score']*100\n",
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed interactions based on users: 2793080\n"
     ]
    }
   ],
   "source": [
    "counts = total.user.value_counts()\n",
    "scores = total[total['user'].isin(counts[counts>=20].index)]\n",
    "print('removed interactions based on users:',total.shape[0]-scores.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed interactions based on tracks: 84686\n"
     ]
    }
   ],
   "source": [
    "no_records = scores.shape[0]\n",
    "counts = scores.track.value_counts()\n",
    "scores = scores[scores['track'].isin(counts[counts>=10].index)]\n",
    "print('removed interactions based on tracks:',no_records-scores.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users: 142245\n",
      "unique tracks: 77962\n",
      "users with insufficient interactions: 425576\n",
      "tracks with insufficient interactions: 18158\n"
     ]
    }
   ],
   "source": [
    "print('unique users:',scores[\"user\"].nunique())\n",
    "print('unique tracks:',scores[\"track\"].nunique())\n",
    "print('users with insufficient interactions:',total['user'].nunique() - scores['user'].nunique())\n",
    "print('tracks with insufficient interactions:',total['track'].nunique() - scores['track'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informed_train_valid(rating_df, train_ratio):\n",
    "    \n",
    "    split_cut = np.int(np.round(rating_df.shape[0] * train_ratio))\n",
    "    train_df = rating_df.iloc[0:split_cut]\n",
    "    test_df = rating_df.iloc[split_cut::]\n",
    "    test_df = test_df[(test_df['user'].isin(train_df['user'])) & (test_df['track'].isin(train_df['track']))]\n",
    "    \n",
    "    id_cols = ['user', 'track']\n",
    "    trans_cat_train = dict()\n",
    "    trans_cat_test = dict()\n",
    "    encoders= dict()\n",
    "    for k in id_cols:\n",
    "        cate_enc = preprocessing.LabelEncoder()\n",
    "        trans_cat_train[k] = cate_enc.fit_transform(train_df[k].values)\n",
    "        trans_cat_test[k] = cate_enc.transform(test_df[k].values)\n",
    "        encoders[k]=cate_enc\n",
    "        \n",
    "# --- Encode ratings:\n",
    "    cate_enc = preprocessing.LabelEncoder()\n",
    "    ratings = dict()\n",
    "    ratings['train'] = cate_enc.fit_transform(train_df['score'])\n",
    "    ratings['test'] = cate_enc.transform(test_df['score'])\n",
    "    \n",
    "    n_users = len(np.unique(trans_cat_train['user']))\n",
    "    n_items = len(np.unique(trans_cat_train['track']))\n",
    "    train = coo_matrix((ratings['train'], (trans_cat_train['user'],trans_cat_train['track'])), shape=(n_users, n_items))\n",
    "    test = coo_matrix((ratings['test'], (trans_cat_test['user'],trans_cat_test['track'])), shape=(n_users, n_items))\n",
    "    \n",
    "    return train, test, train_df,test_df,encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, train_df,valid_df,encoders = informed_train_valid(scores, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116929, 25615)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()['user'],valid_df.nunique()['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=10, init='random', random_state=28)\n",
    "userF = model.fit_transform(train)\n",
    "trackF = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('user_MF_features',userF)\n",
    "np.save('item_MF_features',trackF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user matrix shape: (116929, 10) item matrix shape: (10, 58863)\n"
     ]
    }
   ],
   "source": [
    "print('user matrix shape:',userF.shape,'item matrix shape:',trackF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_metric(x,y):\n",
    "    return cosine_distances(x[None,...],y[None,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nbrs = NearestNeighbors(n_neighbors=5,metric='cosine')\n",
    "track_nbrs = NearestNeighbors(n_neighbors=5,metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Fit time: ---- 384.4542820453644 Seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "user_nbrs.fit(userF)\n",
    "print('---- Fit time: ----',(time.time() - start_time),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Fit time: ---- 167.835923910141 Seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "track_nbrs.fit(trackF.T)\n",
    "print('---- Fit time: ----',(time.time() - start_time),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_user_recommend(encoder,user_id,playlist_size):\n",
    "    index = encoder.transform(np.array(user_id).reshape(-1,1))\n",
    "    user_features = userF[index]\n",
    "    nneighbours = user_nbrs.kneighbors(user_features,n_neighbors=5,return_distance=False)\n",
    "    nneighbours_index = encoder.inverse_transform(nneighbours.squeeze())\n",
    "    nneighbours_interactions = train_df.loc[train_df['user'].isin(nneighbours_index)]\n",
    "    gp = nneighbours_interactions.groupby('track')\n",
    "    tr_fr = gp.apply(lambda x:len(x))\n",
    "    tr_fr = tr_fr.sort_values(ascending=False)\n",
    "    recs = tr_fr.iloc[:playlist_size].index.values\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_recommend(encoder,user_id,playlist_size):\n",
    "    #TODO be jaye yedoone ahang favourite chandta dar nazar gerefte she.\n",
    "    fav_items = train_df.loc[train_df['user'] == user_id].sort_values(by='score',ascending=False)[:10]\n",
    "    fav_scores = fav_items['score']\n",
    "    choice = np.random.choice(fav_scores,p=np.exp(fav_scores)/np.sum(np.exp(fav_scores)))\n",
    "    fav_item = fav_items.loc[fav_items['score']==choice].iloc[0]['track']\n",
    "    fav_index = encoder.transform(np.array(fav_item).reshape(-1,1))\n",
    "    fav_features = trackF.T[fav_index]\n",
    "    nneighbours = track_nbrs.kneighbors(fav_features,n_neighbors=playlist_size,return_distance=False)\n",
    "    nneighbours_index = encoder.inverse_transform(nneighbours.squeeze())\n",
    "    return nneighbours_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "item_recs = item_item_recommend(encoders['track'],train_df['user'][2],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "user_recs = user_user_recommend(encoders['user'],train_df['user'][2],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repitetivesNo(df,user_id,recs):\n",
    "    temp = df.loc[df['user']==user_id]\n",
    "    return len(temp.loc[temp['track'].isin(recs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(rating_df, no_users, no_items_per_user):\n",
    "    gb = rating_df.groupby('user')\n",
    "    test_df = pd.concat([gb.get_group(group)[:no_items_per_user] for i,group in enumerate(gb.groups) if i < no_users])\n",
    "    train_df = pd.concat([rating_df,test_df]).drop_duplicates(keep=False)\n",
    "    test_df =  test_df.loc[(test_df['user'].isin(train_df['user']) & (test_df['track'].isin(train_df['track'])))]\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(repitetivesNo(valid_df,train_df['user'][2],user_recs))\n",
    "print(repitetivesNo(valid_df,train_df['user'][2],item_recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.3 s ± 116 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "item_item_recommend(encoders['track'],train_df['user'][2],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbookpro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1 s ± 756 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "user_user_recommend(encoders['user'],train_df['user'][2],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using surpirse library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate,PredefinedKFold\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(rating_df, no_users, no_items_per_user):\n",
    "    gb = rating_df.groupby('user')\n",
    "    test_df = pd.concat([gb.get_group(group)[:no_items_per_user] for i,group in enumerate(gb.groups) if i < no_users])\n",
    "    train_df = pd.concat([rating_df,test_df]).drop_duplicates(keep=False)\n",
    "    test_df =  test_df.loc[(test_df['user'].isin(train_df['user']) & (test_df['track'].isin(train_df['track'])))]\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_valid_split(scores,no_users=1000,no_items_per_user=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13730140, 3) (5000, 3)\n",
      "142245 1000\n",
      "77962 1555\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,test_df.shape)\n",
    "print(train_df['user'].nunique(),test_df['user'].nunique())\n",
    "print(train_df['track'].nunique(),test_df['track'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(train_df['score'].min(),train_df['score'].max()))\n",
    "train_ds = Dataset.load_from_df(train_df,reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_ds.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = [(row['user'],row['track'],row['score']) for i,row in test_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "algo = surprise.KNNBaseline(k=5,sim_options={'name':'cosine','user_based':False})\n",
    "algo.fit(trainset)\n",
    "print('training time:',time.time()-start_time,'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "predictions = algo.test(testset)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "print('prediction time:',time.time()-start_time,'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=10)\n",
    "\n",
    "print('map@k:',sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print('mar@k:',sum(rec for rec in recalls.values()) / len(recalls))\n",
    "print('r2-score:',metrics.r2_score(predictions_df['r_ui'],predictions_df['est']))\n",
    "print('MSE:',metrics.mean_squared_error(predictions_df['r_ui'],predictions_df['est']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
